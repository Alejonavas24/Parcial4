
---
title: "Parcial 4 "
author: "Manuel Alejandro Navas, German Bernal Ladino, Alejandro Duarte, Jaisson Machado , Kevin Nivia"
date: "28 de Noviembre de 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    collapsed: true
    smooth_scroll: true
    theme: journal
    highlight: kate
    df_print: paged
    code_folding: show
    
---


```{r echo=FALSE}
set.seed(27811)
library(dplyr,warn.conflicts = FALSE)
library(modeest,warn.conflicts = FALSE)
library(descr, warn.conflicts = FALSE)
library(ggplot2, warn.conflicts = FALSE)
library(kableExtra, warn.conflicts = FALSE)
library(moments, warn.conflicts =  FALSE)
library(plotrix, warn.conflicts =  FALSE)
library(readxl, warn.conflicts =  FALSE)
library(plotly, warn.conflicts = FALSE)
library(tseries, warn.conflicts = FALSE)
library(cowplot, warn.conflicts = FALSE)
library(devtools, warn.conflicts = FALSE)
```
# Actividad 1
## Punto A 
 Crear una muestra aleatoria de tamaño 120 
```{r}
#primero leemos el excel y lo guardamos en un data frame en este caso :

Blackfriday=data.frame(read_xlsx("./Blackfriday.xlsx"))
#Despues establecemos el tamaño de la muestra y con ese tamaño usamos la funcion sample:
n=120
muestra=sample(1:nrow(Blackfriday),size=n,replace=FALSE)
#Finalmente relacionamos nuestra muestra con los datos obtenidos del excel:
datosfinales = Blackfriday[muestra, ]
datosfinales

```
 
## Punto B
### Gender
```{r}
datosproblema=data.frame(table(datosfinales$Gender))
datosproblema
valores= datosproblema$Freq
nombres_porcentajes=c("Mujer","Hombre")
porcentajes <- (valores / sum(valores)) * 100
colores <- c("#3498db", "#e74c3c")
plot_ly(labels = nombres_porcentajes, values = porcentajes, type = "pie",
        textinfo = "label+percent", text = datosproblema$Var1 , marker = list(colors = colores)) %>%
  layout(title = list(font="Porcentajes Entre Hombre y Mujer"),
         showlegend = FALSE,  # Ocultar la leyenda
         margin = list(l = 20, r = 0, b = 0, t = 30),  # Ajustar márgenes
         paper_bgcolor = "white",  # Fondo blanco
         plot_bgcolor = "white",  # Fondo blanco
         font = list(family = "Arial", size = 14),  # Fuente y tamaño de texto
         titlefont = list(size = 18),  # Tamaño del título
         annotations = list(text = "Fuente: Datos de ejemplo", showarrow = FALSE,
                            x = 0.8, y = -0.15))  # Nota de fuente

```


Al ser una variable cualitativa no podemos obtener sus medidas de tendencia central, sin embargo como se vera mas a delante la usaremos para generar grupos de datos y asi hacer su respectivo analisis 


### City_category

```{r}
datosproblema=data.frame(table(datosfinales$City_Category))
datosproblema
valores= datosproblema$Freq
nombres_porcentajes=c("CITY A","CITY B","CITY C")
porcentajes <- (valores / sum(valores)) * 100
colores <- c("#BFCDFF", "#E4FFBF","#B8FFD9")
plot_ly(labels = nombres_porcentajes, values = datosproblema$Freq, type = "pie",
        textinfo = "label+percent", text = datosproblema$Var1 , marker = list(colors = colores)) %>%
  layout(title = list(font="Porcentajes de ciudades en la muestra"),
         showlegend = FALSE,  # Ocultar la leyenda
         margin = list(l = 20, r = 0, b = 0, t = 30),  # Ajustar márgenes
         paper_bgcolor = "white",  # Fondo blanco
         plot_bgcolor = "white",  # Fondo blanco
         font = list(family = "Arial", size = 14),  # Fuente y tamaño de texto
         titlefont = list(size = 18),  # Tamaño del título
         annotations = list(text = "Fuente: Datos de ejemplo", showarrow = FALSE,
                            x = 0.8, y = -0.15))  # Nota de fuente

```


### income 
 
```{r}
datosproblema=datosfinales$Income
Media_Datos=median(datosproblema)
Moda=mfv(datosproblema)
Promedio=mean(datosproblema)

#hist(datosproblema)
g1 = ggplot(data = data.frame(datosproblema),mapping = aes(x = datosproblema)) +
  geom_histogram(bins = 20,colour="white",fill="#FFEA89")+
            labs(title = "Histograma income", y ="Cantidad") +
            geom_vline(aes(xintercept= Promedio ,color ="MEDIA"),linetype = "dashed",linewidth = 0.5) +
            geom_vline(aes(xintercept= Media_Datos,color = "MEDIANA"),linetype = "dashed",linewidth = 1) + 
           scale_color_manual(name = "Informacion",values = c(MEDIANA ="blue" ,MEDIA = "red",MODA ="purple"))
g1
#boxplot(datosproblema, col="#BF89FF",xlab="Habitantes",ylab="Edad")
#stripchart(datosproblema, method = "jitter", pch = 19, add = TRUE, col = "blue")
```

Ahora podrmos sacar las medidas de tendencia central

```{r}
cat("la media de los datos es", Media_Datos)

```
```{r}
cat("El promedio de los datos es",Promedio)
```
```{r}
cat("los valores que mas se repiten o la moda es:",Moda)

```
Esto significa que no hay un solo dato que se repita mas veces que los demas, esa es la razon de que aparezcan varios datos como moda 

Tambien podemos ver su grafico de dispercion 
```{r}
plot(datosproblema,col="green",xlab="Personas",ylab="Income")
```

Ahora bien teniendo en cuenta que las primeras dos son variables cualitativas vamos a hacer un pequeño analisis usando estas variables para agrupar los datos de la variable Income 

Aca podemos ver una compraracion entre las medias de los income agrupados entre generos F Y M
```{r}
MediEstado= table(datosfinales %>% group_by(Gender=Gender) %>% summarise(MediaAritmetica=mean(Income)))

barplot(MediEstado,
        main="Comparacion entre medias ingresos",          #C) Título principal     
        xlab="Agrupacion por generos",                   #D) Tíulo del eje X
        ylab="",                   #E) Título del eje Y
        legend = rownames(MediEstado),
         ylim = c(0, 1.5),
        col=c("#FFBEBE","#D7BEFF")
        )

```

Con la grafica enterior podemos ver que no existe una gran diferencia en la media de ingresos por generos 

```{r}
MedianaEstado= table(datosfinales %>% group_by(Gender=Gender) %>% summarise(MediaAritmetica=median(Income)))

barplot(MedianaEstado,
        main="Comparacion entre mediana ingresos",          #C) Título principal     
        xlab="Agrupacion por generos",                   #D) Tíulo del eje X
        ylab="",                   #E) Título del eje Y
        legend = rownames(MediEstado),
         ylim = c(0, 1.5),
        col=c("#EAFF8B","#BEFFF2")
        )
```
Aasi como en la compaaracion anterior podemos ver que si separamos loss daatos entre generos la diferencia es casi nula 

ahora teniendo en cuenta que no hay mucha diferencia cuando se agrupa en generos intentemos agruparlos por ciudades 

```{r}
MediEstado= table(datosfinales %>% group_by(City_Category=City_Category) %>% summarise(MediaAritmetica=mean(Income)))

barplot(MediEstado,
        main="Comparacion entre medias ingresos",          #C) Título principal     
        xlab="Agrupacion por categoria de ciudad",                   #D) Tíulo del eje X
        ylab="",                   #E) Título del eje Y
        legend = rownames(MediEstado),
         ylim = c(0, 1.5),
        col=c("#FFBEBE","#FBFFAF","#AFFFC4")
        )
```
```{r}
MedianEstado= table(datosfinales %>% group_by(City_Category=City_Category) %>% summarise(MediaAritmetica=median(Income)))

barplot(MedianEstado,
        main="Comparacion entre mediana ingresos",          #C) Título principal     
        xlab="Agrupacion por categoria de ciudad",                   #D) Tíulo del eje X
        ylab="",                   #E) Título del eje Y
        legend = rownames(MedianEstado),
         ylim = c(0, 1.5),
        col=c("#7B7E4E","#4E7E59","#7E4E4E")
)
```
Al igual que agrupandolo por generos podemos ver como al ser agrupadas por categoria de ciudad los resultados dan casi igual lo cual nos indicaria que la muestra tomada anteriormente se podria pensar que tiene una distribucion nomrla o en su defecto muy similar a una distribuvion normal 

## Punto C 
primero cacularemos la media y desviacion estandar de la poblacion general 

```{r echo=FALSE}
media_poblacion=mean(Blackfriday$Purchase)
cat("La media de la poblacion es:",media_poblacion)
```
```{r echo=FALSE}
desviacion_Estandar_poblacion=sd(Blackfriday$Purchase)
cat("La desviacion estandar de la poblacion es:",desviacion_Estandar_poblacion)
```

Ahora calcularemos la media y desviacion estandar de la muestra 

```{r echo=FALSE}
media_muestra=mean(datosfinales$Purchase)

cat("La media de la muestra  es:",media_muestra)
```
```{r echo=FALSE}
desviacion_Estandar_muestra=sd(datosfinales$Purchase)
cat("La desviacion estandar de la muestra es:",desviacion_Estandar_muestra)
```

En situiaciones como estas el estimador es la MUESTRA, esto debido a que normalmente se desconocen todos los datos de l apoblacion, por lo cual se toma una muestra lo suficientemente grande para obtener los datos mas cercanos posibles desconociendo la totalidad de los datos de la poblacion 


Ahora miraremos la probabilidad de que la variable media muestral sea mayor o igual que el valor de la
poblacional.


```{r}
z <- round(( mean(Blackfriday$Purchase) - mean(datosfinales$Purchase))/sd(datosfinales$Purchase),2)
probabilidad <- round(pnorm(q=z,mean = 0, sd=1,lower.tail = FALSE),1)

cat("la probabilidad de que la variable media muestral sea mayor o igual que el valor de la
poblacional es de :",(probabilidad*100),"%")
```
Al no haber una inclinacion muy marcada o significativa en que la media muestral sea igual o mayor que la media poblacional se considera que los segos son muy bajos por no decir inexistentes 

## Punto D

```{r}
datosproblema=datosfinales$Purchase
Mediana_Datos=round(median(datosproblema),0)
Moda=mfv(datosproblema)
Promedio=round(mean(datosproblema),0)
sdi=round(sd(datosproblema),0)

#hist(datosproblema)
g1 = ggplot(data = data.frame(datosproblema),mapping = aes(x = datosproblema)) +
  geom_histogram(bins = 20,colour="white",fill="#FFBCFD")+
            labs(title = "Histograma variable PurchaseS", y ="Cantidad") +
            #geom_vline(aes(xintercept= Promedio ,color ="MEDIA"),linetype = "dashed",linewidth = 1) +
            #(aes(xintercept= Media_Datos,color = "MEDIANA"),linetype = "dashed",linewidth = 1) + 
           #scale_color_manual(name = "Informacion",values = c(MEDIANA ="#5DFF00" ,MEDIA = "#6E00FF")) +
          stat_function(fun = dnorm, n = 10000, args = list(mean = Promedio, sd = sdi)) + ylab("") +
  scale_y_continuous(breaks = NULL)
g1
```
Ahora calcularemos la courtosis :

```{r}
curti=kurtosis(datosfinales$Purchase)
cat("la curtosis de la variable purchasae de la muestra aes: ",curti)

```
En una distribución normal, la curtosis es 3. Un valor de curtosis muy cercano a cero, como 0.0069, indica que la distribución tiene colas más ligeras en comparación con una distribución normal

Ahora calcularemos la asimetria con la funcion skewness
```{r}
  datosproblema=datosfinales$Purchase
asimetria=skewness(datosproblema)
cat("la asimetria da :",asimetria)

```
Un sesgo de 0 indica una simetría perfecta en la distribución. Un valor cercano a cero, como 0.0847, sugiere una simetría relativamente buena en la distribución. Valores cercanos a cero indican que la distribución está más cerca de ser simétrica.

```{r}
plot(datosfinales$Purchase, dnorm(datosfinales$Purchase, mean = mean(datosfinales$Purchase), sd = sd(datosfinales$Purchase)), type = "l",
     ylim = c(0, 0.0001), ylab = "", lwd = 2, col = "red")

 x=dnorm(datosfinales$Purchase, mean = mean(datosfinales$Purchase), sd = sd(datosfinales$Purchase))
x
```

En resumen, según los valores obtenidos, la distribución parece ser bastante simétrica (debido al sesgo cercano a cero), pero tiene colas más ligeras que las de una distribución normal, lo que indica una distribución platicúrtica. Sin embargo, es importante recordar que estos valores por sí solos no proporcionan una conclusión definitiva sobre la normalidad de la distribución


# Actividad 2


## Punto A

Se carga la información de la base de datos
IMPORTANTE: Cambiar la ruta en la que tenga su archivo Blackfriday.xlsx en caso de que no la lea el archivo
data <- data.frame(read_xlsx("SU RUTA"))

```{r}
data <- data.frame(read_xlsx("./Blackfriday.xlsx"))
### Se muestran dos formas de hacer el mismo procedimiento,
### primero, creando la función con los datos que se piden,
### segundo, usando una función que generá el nivel de confianza.

### PRIMERA FORMA DE GENERAR EL NIVEL DE CONFIANZA

### media = Media de la columna Purchase de los datos
data_purchase <- data$Purchase
media <- mean(data_purchase)

### z = Cuantil de la distribucion normal estandar
z <- 1.645

### nivel_confianza del 90% = 0.90
nivel_confianza <- 0.90

### n = La cantidad de datos en la columna Purchase
length(data$Purchase)
n <- length(data$Purchase)

### desviacion = desviacion estandar de la muestra
sd(data$Purchase)
desviacion <- sd(data$Purchase)

### error_estandar = Desviacion estandar de la muestra
error_estandar <- desviacion / sqrt(n)

### limite_inferior = Calculo del limite inferior
### limite_superior = Calculo del limite superior
limite_inferior <- media - (z * error_estandar)
limite_superior <- media + (z * error_estandar)

### Se muestra en un dataframe todos los datos
interval_m <- data.frame(n, media,nivel_confianza , desviacion, z, error_estandar, limite_inferior, limite_superior)
interval_conf <- data.frame(media, nivel_confianza, limite_inferior, limite_superior)
interval_conf


### SEGUNDA FORMA DE GENERAR EL NIVEL DE CONFIANZA
### Se hace uso de la función t.test()
res <- t.test(x = data$Purchase, conf.level = 0.90)
res

```

El intervalo de confianza al 90% para el promedio de la variable PURCHASE,
se encuentra entre [9470.603, 9545.915].

Efectivamente la media poblacional cae en el intervalo, pues la media de la muestra
es 9508.259 y el intervalo es [9470.603, 9545.915].


## PUNTO B

Se muestran dos formas de hacer el mismo procedimiento,
primero, creando la función con los datos que se piden,
segundo, usando una función que generá el nivel de confianza.

```{r}
### Volvemos a inicializar los datos
data <- data.frame(read_xlsx("./Blackfriday.xlsx"))

### Se muestran en la columna Purchase únicamente los valores > 5000
data <- data %>% filter(Purchase > 5000)

### media = Media de la columna Purchase de los datos
data_purchase <- data$Purchase
media <- mean(data_purchase)

### z = Cuantil de la distribucion normal estandar
z <- 1.960

### nivel_confianza del 95% = 0.95
nivel_confianza <- 0.95

### n = La cantidad de datos en la columna Purchase
length(data$Purchase)
n <- length(data$Purchase)

### desviacion = desviacion estandar de la muestra
sd(data$Purchase)
desviacion <- sd(data$Purchase)

### error_estandar = Desviacion estandar de la muestra
error_estandar <- desviacion / sqrt(n)

### limite_inferior = Calculo del limite inferior
### limite_superior = Calculo del limite superior
limite_inferior <- media - (z * error_estandar)
limite_superior <- media + (z * error_estandar)

### Cargar en un dataframe los datos necesarios para el calculo
interval_m <- data.frame(n,media,nivel_confianza,desviacion,z,error_estandar,limite_inferior,limite_superior)
interval_conf <- data.frame(media, nivel_confianza, limite_inferior, limite_superior)
interval_conf

### SEGUNDA FORMA DE GENERAR EL NIVEL DE CONFIANZA
### Se hace uso de la función t.test()
res <- t.test(x = data$Purchase, conf.level = 0.95)
res

```

El intervalo de confianza al 95% para la proporcion de ventas superiores a US$5000
es de [11104.31, 11181.21]; además la proporcion poblacional se encuentra en este intervalo



# Actividad 3

## Punto A

La hipotesis nula se plantea como:
u es menor o igual a el valor real encontrado en la población

La hipotesis alternativa se plantea como:
u es mayor a el valor real encontrado en la población 

```{r}
#poblacion
media_poblacion
desviacion_Estandar_poblacion
#muestra
media_muestra
desviacion_Estandar_muestra

formz3A=(media_muestra-media_poblacion)/(desviacion_Estandar_muestra/sqrt(120))
pnorm(formz3A)
```
El valor de 0.8392467 cae dentro de la región de aceptación de la hipotesis nula, por lo tanto se puede decir que el el valor u es menor o igual al valor real encontrado en la población, por lo tanto se puede decir que las personas compran menos que el valor promedio.

## Punto B

```{r}
muestraP3 <- subset(Blackfriday,select=c(Gender,Purchase))
#tamaño de la muestrs 120
n=120
#se extraen los datos de la población femenina
PoblacionF <- subset(muestraP3,Gender=="F")
muestraF <- sample(PoblacionF$Purchase,size=n,replace=FALSE,prob=NULL)
comprasPromF <- mean(PoblacionF$Purchase)
PromMuestraF <- mean(muestraF)
sdcompraspromF <- sd(PoblacionF$Purchase)
sdPromMuestraF <- sd(muestraF)
#se extraen los datos de la población masculina
PoblacionM <- subset(muestraP3,Gender=="M")
muestraM <- sample(PoblacionM$Purchase,size=n,replace=FALSE,prob=NULL)
ComprasPromM <- mean(PoblacionM$Purchase)
PromMMuestra <- mean(muestraM)
sdcompraspromM <- sd(PoblacionM$Purchase)
sdPromMuestraM <- sd(muestraM)

```
Creamos los filtros para las muestras de genero por Masculino y Femenino. En el dataframe se encuentran como masculino M y femenino F
obtenemos tambien el promedio y la desviación estandar de cada muestra.


Estos son los datos para la poblacion y muestra Femenina
```{r}
cat("La muestra femenina es:",muestraF)
#cat("La población femenina es:",PoblacionF$Purchase)
cat("\nEl promedio de la población femenina es:",comprasPromF)
cat("\nEl promedio de la muestra femenina es:",PromMuestraF)
cat("\nLa desviación estandar de la población femenina es:",sdcompraspromF)
cat("\nLa desviación estandar de la muestra femenina es:",sdPromMuestraF)

```
Estos son los datos para la poblacion y muestra Masculina

```{r}

cat("La muestra masculina es:",muestraM)
#cat("La población femenina es:",PoblacionF$Purchase)
cat("\nEl promedio de la población masculina es:",ComprasPromM)
cat("\nEl promedio de la muestra masculina es:",PromMMuestra)
cat("\nLa desviación estandar de la población masculina es:",sdcompraspromM)
cat("\nLa desviación estandar de la muestra masculina es:",sdPromMuestraM)

```

La hipotesis que platearemos es si hay diferencia entre ambas poblaciones por lo tanto se plantea que H0:μ1-μ2 != media

la hipotesis alternativa se plantearia como
H1:μ1-μ2 = media

```{r}

z3B <- ((PromMMuestra-PromMuestraF))/(sqrt(((sdPromMuestraM*sdPromMuestraM)/120)+((sdPromMuestraF*sdPromMuestraF)/120)))
z3B

pnorm(z3B)
```

Con un nivel de significancia del 5% se puede decir que la diferencia entre el promedio de gastos masculino y el promedio de compras femenino es diferente por lo tanto la hipotesis H0 es correcta y se puede decir que la 

## Punto C

Calcularemos un intervalo de confianza de una cola para las varianzas de la muestra de compras masculino y femenino.
```{r}
if (!require('devtools')) install.packages('devtools')
devtools::install_github('fhernanb/stests', force=TRUE)

stests::var.test(c(sdcompraspromM,sdcompraspromF)) 
```


## Punto D

Tenemos como hipotenis nula que la igualdad de las varianzas de las compras de hombres y mujeres.
H0:sμ1 = sμ2
como hipotesis alternativa se tiene que son diferentes.
H1:sμ1 != sμ2

```{r}

PruebaHipVarianzas <- ((sdcompraspromM*sdcompraspromM)/(sdcompraspromF*sdcompraspromF))

PruebaHipVarianzas

gradosLibertad <- 119/119

valorCritico <- 1.35
valorCritico

```
Con los valores del valor critico que equivale a 1.35 y el valor del estadistico de prueba equivale a 0.99291 se concluye que como el estadistico es menor que el valor critico se rechaza la hipotesis nula.
Por lo tanto la hipotesis alternativa es verdadera entonces la varianza de ambos son diferentes
=======
##Punto c

```{r}
##Se establece primero la media y la desviciación tanto de hombres como de mujeres

media_hombres <- mean(Blackfriday$Purchase[Blackfriday$Gender == "M"])
desviacion_hombres <- sd(Blackfriday$Purchase[Blackfriday$Gender == "M"])


media_mujeres <- mean(Blackfriday$Purchase[Blackfriday$Gender == "F"])
desviacion_mujeres <- sd(Blackfriday$Purchase[Blackfriday$Gender == "F"])

##Ya con esto se calcula el intervalo de confianza

intervalo_confianza <- t.test(Blackfriday$Purchase[Blackfriday$Gender == "M"], Blackfriday$Purchase[Blackfriday$Gender == "F"], conf.level = 0.90)$conf.int

intervalo_confianza

```
Por ello estamos 90% seguros de que la diferencia entre las compras promedio hechas por hombres y mujeres está entre 599.9853 y 767.992 dólares.

##Punto d

```{r}
# Filtrar las compras de mujeres
compras_mujeres <- Blackfriday$Purchase[Blackfriday$Gender == "F"]

# Calcular el intervalo de confianza para la varianza
n <- length(compras_mujeres)
grados_libertad <- n - 1
alpha <- 0.05  # Nivel de confianza del 95%

# Calcular los cuantiles de la distribución chi-cuadrado
quantil_inf <- qchisq(1 - alpha/2, df = grados_libertad)
quantil_sup <- qchisq(alpha/2, df = grados_libertad)

# Calcular el intervalo de confianza
intervalo_confianza <- c((n - 1) * var(compras_mujeres) / quantil_inf, (n - 1) * var(compras_mujeres) / quantil_sup)

# Mostrar el intervalo de confianza
print(intervalo_confianza)

```
De esta forma podemos estar 95% seguros de que la totalidad de las compras echas por mujeres varian en el intervalo de 21.799.520 y 22.941.489 doláres
```{r}
# Almacenar el intervalo de confianza calculado en una variable
intervalo_confianza_varianza <- c((n - 1) * var(compras_mujeres) / quantil_inf, (n - 1) * var(compras_mujeres) / quantil_sup)

# Crear un vector con los datos a graficar
datos_grafico <- c(var(compras_mujeres), intervalo_confianza_varianza[1], intervalo_confianza_varianza[2])

# Etiquetas para las barras
nombres_barras <- c("Estimación puntual", "Límite inferior", "Límite superior")

# Crear el gráfico de barras
barplot(datos_grafico, names.arg = nombres_barras, col = c("lightblue", "lightgreen", "lightgreen"),
        ylim = c(0, max(intervalo_confianza_varianza)*1.2), main = "Intervalo de confianza para la varianza",
        ylab = "Valores", xlab = "Varianza")

# Agregar una leyenda
legend("topright", legend = c("Estimación puntual", "Intervalo de confianza"), fill = c("lightblue", "lightgreen"))
```



# Actividad 3 

